import os
import re
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_recommenders as tfrs
from sklearn.model_selection import train_test_split


# ë°ì´í„° ë¡œë“œ

DATA_PATH = "hansik_cleaned.csv"
assert os.path.exists(DATA_PATH), f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}"

df = pd.read_csv(DATA_PATH)
print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", df.shape)
print("ğŸ“‹ ì»¬ëŸ¼:", df.columns.tolist())

# íƒœê·¸ ì»¬ëŸ¼ ì •ì œ
def split_tags(x):
    if pd.isna(x):
        return []
    parts = re.split(r"[,\|/]", str(x))
    return [p.strip() for p in parts if p.strip()]

df["tag_list"] = df["tags"].apply(split_tags)
df = df[df["tag_list"].map(len) > 0].copy()


# íƒœê·¸ ê¸°ë°˜ ê°€ì§œ ì‚¬ìš©ì-ë ˆì‹œí”¼ ìƒí˜¸ì‘ìš© ìƒì„±

pairs = []
for rid, tags in zip(df["recipe_id"], df["tag_list"]):
    for t in tags:
        pairs.append((f"tag::{t}", str(rid)))

interactions = pd.DataFrame(pairs, columns=["user_id", "recipe_id"]).drop_duplicates()
print("ğŸ§© ìƒí˜¸ì‘ìš© ë°ì´í„° í¬ê¸°:", interactions.shape)

# í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
train_df, val_df = train_test_split(interactions, test_size=0.1, random_state=42)

user_ids = sorted(interactions["user_id"].unique().tolist())
recipe_ids = sorted(df["recipe_id"].astype(str).unique().tolist())


# TensorFlow Dataset ë³€í™˜

def to_ds(pdf):
    return tf.data.Dataset.from_tensor_slices({
        "user_id": tf.constant(pdf["user_id"].values),
        "recipe_id": tf.constant(pdf["recipe_id"].astype(str).values),
    })

BATCH_SIZE = 1024
train_ds = to_ds(train_df).shuffle(200_000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = to_ds(val_df).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
candidates_ds = tf.data.Dataset.from_tensor_slices(tf.constant(recipe_ids)).batch(256)

# TFRS Retrieval ëª¨ë¸ ì •ì˜

class TagRetrievalModel(tfrs.models.Model):
    def __init__(self, user_vocab, recipe_vocab, embed_dim=64):
        super().__init__()
        self.user_model = tf.keras.Sequential([
            tf.keras.layers.StringLookup(vocabulary=user_vocab, mask_token=None),
            tf.keras.layers.Embedding(len(user_vocab) + 1, embed_dim),
        ])
        self.recipe_model = tf.keras.Sequential([
            tf.keras.layers.StringLookup(vocabulary=recipe_vocab, mask_token=None),
            tf.keras.layers.Embedding(len(recipe_vocab) + 1, embed_dim),
        ])
        self.task = tfrs.tasks.Retrieval(
            metrics=tfrs.metrics.FactorizedTopK(candidates=candidates_ds.map(self.recipe_model))
        )

    def compute_loss(self, features, training=False):
        user_emb = self.user_model(features["user_id"])
        recipe_emb = self.recipe_model(features["recipe_id"])
        return self.task(user_emb, recipe_emb)


# ëª¨ë¸ í•™ìŠµ

model = TagRetrievalModel(user_ids, recipe_ids, embed_dim=64)
model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))

print("\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
history = model.fit(train_ds, validation_data=val_ds, epochs=3, verbose=2)
print("âœ… í•™ìŠµ ì™„ë£Œ!")


# í…ŒìŠ¤íŠ¸ ì¶”ì²œ í•¨ìˆ˜

recipe_embs = model.recipe_model(tf.constant(recipe_ids))

def recommend_for_tags(pref_tags, top_k=5):
    tag_user_ids = [f"tag::{t}" for t in pref_tags]
    user_embs = model.user_model(tf.constant(tag_user_ids))
    user_emb = tf.reduce_mean(user_embs, axis=0, keepdims=True)
    scores = tf.linalg.matmul(user_emb, recipe_embs, transpose_b=True)[0].numpy()
    top_idx = np.argsort(-scores)[:top_k]
    top_recipes = df.iloc[top_idx]
    return top_recipes[["recipe_id", "name", "tags", "calories", "img_url"]]


# ì¶”ì²œ í…ŒìŠ¤íŠ¸

print("\nğŸ” [TEST] ì„ í˜¸ íƒœê·¸=['ê³ ë‹¨ë°±','ì €ì—¼']")
result = recommend_for_tags(["ê³ ë‹¨ë°±", "ì €ì—¼"], top_k=5)
print(result)
